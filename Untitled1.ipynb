{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05cc94bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models,layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d6eb525",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=\"C:\\\\Users\\\\SHRIRAJ\\\\Pictures\\\\training images\\\\train\"\n",
    "train_data=ImageDataGenerator(\n",
    "rescale=1./255,horizontal_flip=True,rotation_range=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c528badf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 105 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "size=256\n",
    "train_gen=train_data.flow_from_directory(\n",
    "    \"C:\\\\Users\\\\SHRIRAJ\\\\Pictures\\\\training images\\\\train\",\n",
    "    target_size=(size,size),class_mode=\"sparse\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e70720c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.06666667 0.08627451 0.09803922]\n",
      "   [0.06519367 0.08480151 0.09656622]\n",
      "   [0.06413186 0.08235294 0.09411766]\n",
      "   ...\n",
      "   [0.04290736 0.04705883 0.05482533]\n",
      "   [0.04313726 0.04705883 0.05490196]\n",
      "   [0.04313726 0.04705883 0.05490196]]\n",
      "\n",
      "  [[0.06666667 0.08627451 0.09803922]\n",
      "   [0.06601161 0.08561945 0.09738415]\n",
      "   [0.06331392 0.08235294 0.09411766]\n",
      "   ...\n",
      "   [0.04313726 0.04705883 0.05490196]\n",
      "   [0.04379232 0.04705883 0.05490196]\n",
      "   [0.04461027 0.04705883 0.05490196]]\n",
      "\n",
      "  [[0.0667433  0.08627451 0.09803922]\n",
      "   [0.06666667 0.08627451 0.09803922]\n",
      "   [0.06299423 0.08260208 0.09436678]\n",
      "   ...\n",
      "   [0.0468097  0.04705883 0.05490196]\n",
      "   [0.04535239 0.04762764 0.05376434]\n",
      "   [0.04289855 0.04844559 0.05212845]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.07058824 0.07058824 0.07058824]\n",
      "   [0.07058824 0.07058824 0.07058824]\n",
      "   [0.07058824 0.07058824 0.07058824]\n",
      "   ...\n",
      "   [0.05465284 0.05465284 0.05465284]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.0509804  0.0509804  0.0509804 ]]\n",
      "\n",
      "  [[0.07058824 0.07058824 0.07058824]\n",
      "   [0.07058824 0.07058824 0.07058824]\n",
      "   [0.07042536 0.07042536 0.07042536]\n",
      "   ...\n",
      "   [0.05490196 0.05490196 0.05490196]\n",
      "   [0.05163546 0.05163546 0.05163546]\n",
      "   [0.0509804  0.0509804  0.0509804 ]]\n",
      "\n",
      "  [[0.06822593 0.06822593 0.06822593]\n",
      "   [0.06740799 0.06740799 0.06740799]\n",
      "   [0.06666667 0.06666667 0.06666667]\n",
      "   ...\n",
      "   [0.05490196 0.05490196 0.05490196]\n",
      "   [0.0524534  0.0524534  0.0524534 ]\n",
      "   [0.0509804  0.0509804  0.0509804 ]]]\n",
      "\n",
      "\n",
      " [[[0.13851361 0.15027831 0.18557243]\n",
      "   [0.13943039 0.1511951  0.18648922]\n",
      "   [0.1403472  0.1521119  0.18740602]\n",
      "   ...\n",
      "   [0.3137255  0.29280534 0.2823491 ]\n",
      "   [0.3150273  0.28365475 0.2758116 ]\n",
      "   [0.29563096 0.26425838 0.25641525]]\n",
      "\n",
      "  [[0.13595314 0.14771785 0.18301196]\n",
      "   [0.13572395 0.14748865 0.18278277]\n",
      "   [0.13549475 0.14725946 0.18255357]\n",
      "   ...\n",
      "   [0.3137255  0.29188854 0.2816615 ]\n",
      "   [0.31525648 0.28388393 0.2760408 ]\n",
      "   [0.29173458 0.26036203 0.2525189 ]]\n",
      "\n",
      "  [[0.14770728 0.15947199 0.19476612]\n",
      "   [0.1467905  0.15855521 0.19384933]\n",
      "   [0.1458737  0.15763842 0.19293253]\n",
      "   ...\n",
      "   [0.3137255  0.29097176 0.2809739 ]\n",
      "   [0.3154857  0.28411314 0.27627   ]\n",
      "   [0.28783822 0.25646567 0.24862252]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.15686275 0.15294118 0.17254902]\n",
      "   [0.14605574 0.14213417 0.16174202]\n",
      "   [0.14371902 0.13979745 0.15940529]\n",
      "   ...\n",
      "   [0.1115708  0.09588452 0.08411982]\n",
      "   [0.1113416  0.09565533 0.08389062]\n",
      "   [0.1111124  0.09542613 0.08366141]]\n",
      "\n",
      "  [[0.15686275 0.15294118 0.17254902]\n",
      "   [0.14490975 0.14098819 0.16059603]\n",
      "   [0.1444066  0.14048503 0.16009288]\n",
      "   ...\n",
      "   [0.11196533 0.09627905 0.08451435]\n",
      "   [0.11219453 0.09650826 0.08474355]\n",
      "   [0.11242373 0.09673745 0.08497275]]\n",
      "\n",
      "  [[0.15686275 0.15294118 0.17254902]\n",
      "   [0.14376375 0.13984218 0.15945002]\n",
      "   [0.1450942  0.14117263 0.16078047]\n",
      "   ...\n",
      "   [0.10980393 0.09411766 0.08235294]\n",
      "   [0.10980393 0.09411766 0.08235294]\n",
      "   [0.10980393 0.09411766 0.08235294]]]\n",
      "\n",
      "\n",
      " [[[1.         1.         0.9843138 ]\n",
      "   [1.         1.         0.9843138 ]\n",
      "   [1.         1.         0.9843138 ]\n",
      "   ...\n",
      "   [0.16610675 0.08767536 0.05238125]\n",
      "   [0.16477156 0.08634017 0.05104605]\n",
      "   [0.16974017 0.09130879 0.05601468]]\n",
      "\n",
      "  [[1.         1.         0.9843138 ]\n",
      "   [1.         1.         0.9843138 ]\n",
      "   [1.         1.         0.9843138 ]\n",
      "   ...\n",
      "   [0.1868005  0.10836912 0.073075  ]\n",
      "   [0.19176912 0.11333775 0.07804362]\n",
      "   [0.18692158 0.10849021 0.07319609]]\n",
      "\n",
      "  [[1.         1.         0.9843138 ]\n",
      "   [1.         1.         0.9843138 ]\n",
      "   [1.         1.         0.9843138 ]\n",
      "   ...\n",
      "   [0.16742407 0.0889927  0.05369857]\n",
      "   [0.16174564 0.08331426 0.04802015]\n",
      "   [0.16078432 0.08235294 0.04705883]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.10389811 0.07370484 0.07370484]\n",
      "   [0.04843597 0.01766424 0.01682309]\n",
      "   [0.14922808 0.12200537 0.11619559]\n",
      "   ...\n",
      "   [0.9991701  0.9991701  1.        ]\n",
      "   [0.9960785  0.9960785  1.        ]\n",
      "   [0.9960785  0.9960785  1.        ]]\n",
      "\n",
      "  [[0.495309   0.48027223 0.45740214]\n",
      "   [0.58757067 0.57580596 0.5484657 ]\n",
      "   [0.5790529  0.5672882  0.5413677 ]\n",
      "   ...\n",
      "   [0.9998799  0.9998799  1.        ]\n",
      "   [0.9960785  0.9960785  1.        ]\n",
      "   [0.9960785  0.9960785  1.        ]]\n",
      "\n",
      "  [[0.5498067  0.538042   0.5169958 ]\n",
      "   [0.54128903 0.5295243  0.5098977 ]\n",
      "   [0.5187629  0.50629777 0.4880908 ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [0.9967329  0.9967329  1.        ]\n",
      "   [0.9960785  0.9960785  1.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.41810504 0.38014096 0.34735006]\n",
      "   [0.46449646 0.41727108 0.38197696]\n",
      "   [0.46383044 0.4155199  0.37221625]\n",
      "   ...\n",
      "   [0.34713084 0.3364385  0.34124938]\n",
      "   [0.31733775 0.29293305 0.29547128]\n",
      "   [0.3047975  0.27751324 0.27876484]]\n",
      "\n",
      "  [[0.40930504 0.36797535 0.33649197]\n",
      "   [0.4587654  0.40948102 0.3746044 ]\n",
      "   [0.46663275 0.41611063 0.37375283]\n",
      "   ...\n",
      "   [0.33391243 0.3281908  0.33339897]\n",
      "   [0.3091326  0.2934745  0.2929812 ]\n",
      "   [0.30446413 0.28627452 0.28360462]]\n",
      "\n",
      "  [[0.39112803 0.34020302 0.3122655 ]\n",
      "   [0.44074976 0.38370588 0.35099176]\n",
      "   [0.46367428 0.40747854 0.36735952]\n",
      "   ...\n",
      "   [0.33204514 0.3316281  0.33685765]\n",
      "   [0.29620528 0.28490043 0.28271067]\n",
      "   [0.2912814  0.27559513 0.27167356]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7919905  0.7684611  0.77630424]\n",
      "   [0.79254663 0.7690172  0.77686036]\n",
      "   [0.7926016  0.7690722  0.7769153 ]\n",
      "   ...\n",
      "   [0.34274337 0.29689506 0.23974203]\n",
      "   [0.285029   0.2567708  0.21789673]\n",
      "   [0.26744074 0.24088001 0.21294247]]\n",
      "\n",
      "  [[0.8000001  0.77647066 0.7843138 ]\n",
      "   [0.7961402  0.7726108  0.7804539 ]\n",
      "   [0.78953546 0.76600605 0.7738492 ]\n",
      "   ...\n",
      "   [0.3420161  0.3166841  0.27029908]\n",
      "   [0.2972175  0.27590552 0.24803649]\n",
      "   [0.27774206 0.25642416 0.23649634]]\n",
      "\n",
      "  [[0.7962452  0.7739674  0.7843138 ]\n",
      "   [0.792796   0.77053916 0.7809273 ]\n",
      "   [0.78521776 0.7629818  0.77341163]\n",
      "   ...\n",
      "   [0.34025756 0.32331955 0.28377107]\n",
      "   [0.3040453  0.28443745 0.26341137]\n",
      "   [0.2779312  0.25832334 0.24263708]]]\n",
      "\n",
      "\n",
      " [[[0.40155515 0.4878297  0.23684928]\n",
      "   [0.37675652 0.47227123 0.2151307 ]\n",
      "   [0.3665055  0.45850122 0.22989532]\n",
      "   ...\n",
      "   [0.27469444 0.370603   0.12030206]\n",
      "   [0.28951645 0.38609874 0.1331029 ]\n",
      "   [0.30433849 0.40159452 0.14590372]]\n",
      "\n",
      "  [[0.4096399  0.4959144  0.24493401]\n",
      "   [0.38012516 0.47361872 0.21782562]\n",
      "   [0.36785296 0.46119612 0.22585295]\n",
      "   ...\n",
      "   [0.34236002 0.44039926 0.18330833]\n",
      "   [0.35044476 0.448484   0.1920668 ]\n",
      "   [0.3585295  0.45656872 0.20082526]]\n",
      "\n",
      "  [[0.41772464 0.5039992  0.25301874]\n",
      "   [0.3834938  0.47496617 0.22052053]\n",
      "   [0.36920044 0.46389103 0.22181056]\n",
      "   ...\n",
      "   [0.34518713 0.43820342 0.16655837]\n",
      "   [0.33575496 0.42675006 0.1483677 ]\n",
      "   [0.32632273 0.4152967  0.13017705]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.11518879 0.17793389 0.04678978]\n",
      "   [0.16032858 0.22307368 0.08182364]\n",
      "   [0.20546836 0.26821345 0.1168575 ]\n",
      "   ...\n",
      "   [0.2767571  0.3803922  0.10191625]\n",
      "   [0.25654188 0.3475579  0.09676294]\n",
      "   [0.2946125  0.37696543 0.13818176]]\n",
      "\n",
      "  [[0.32522056 0.38544115 0.20981206]\n",
      "   [0.3312841  0.3894835  0.21452814]\n",
      "   [0.33734763 0.3935259  0.21924424]\n",
      "   ...\n",
      "   [0.27608335 0.3803922  0.10663234]\n",
      "   [0.26327914 0.3576638  0.09474176]\n",
      "   [0.27709556 0.3594485  0.1267284 ]]\n",
      "\n",
      "  [[0.36312267 0.41331986 0.23920445]\n",
      "   [0.37188113 0.4214046  0.24594174]\n",
      "   [0.38063958 0.42948934 0.25267902]\n",
      "   ...\n",
      "   [0.2754096  0.3803922  0.11134844]\n",
      "   [0.27001643 0.36776972 0.09272058]\n",
      "   [0.25957862 0.34193155 0.11527501]]]\n",
      "\n",
      "\n",
      " [[[0.6509804  0.75294125 0.8431373 ]\n",
      "   [0.6509804  0.75294125 0.8431373 ]\n",
      "   [0.6509804  0.75294125 0.8431373 ]\n",
      "   ...\n",
      "   [0.30621678 0.36453873 0.3919897 ]\n",
      "   [0.30949274 0.36290073 0.3903517 ]\n",
      "   [0.31276873 0.36126274 0.38871372]]\n",
      "\n",
      "  [[0.6509804  0.75294125 0.8431373 ]\n",
      "   [0.6509804  0.75294125 0.8431373 ]\n",
      "   [0.6509804  0.75294125 0.8431373 ]\n",
      "   ...\n",
      "   [0.32155716 0.3568685  0.38431948]\n",
      "   [0.32238474 0.35767886 0.38512987]\n",
      "   [0.32320377 0.3584979  0.38594887]]\n",
      "\n",
      "  [[0.6509804  0.75294125 0.8431373 ]\n",
      "   [0.6509804  0.75294125 0.8431373 ]\n",
      "   [0.6509804  0.75294125 0.8431373 ]\n",
      "   ...\n",
      "   [0.3254009  0.360695   0.38814598]\n",
      "   [0.3254902  0.36078432 0.38823533]\n",
      "   [0.3254902  0.36078432 0.38823533]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8470589  0.8745099  0.8980393 ]\n",
      "   [0.8470589  0.8745099  0.8980393 ]\n",
      "   [0.8470589  0.8745099  0.8980393 ]\n",
      "   ...\n",
      "   [0.17263839 0.17655995 0.14518741]\n",
      "   [0.17647347 0.18039504 0.14902249]\n",
      "   [0.18030858 0.18423015 0.15285759]]\n",
      "\n",
      "  [[0.8470589  0.8745099  0.8980393 ]\n",
      "   [0.8470589  0.8745099  0.8980393 ]\n",
      "   [0.847056   0.874507   0.8980364 ]\n",
      "   ...\n",
      "   [0.17108974 0.17574096 0.14655735]\n",
      "   [0.17565447 0.17957604 0.14820349]\n",
      "   [0.17948958 0.18341115 0.1520386 ]]\n",
      "\n",
      "  [[0.84485894 0.8723099  0.89583933]\n",
      "   [0.8440399  0.8714909  0.8950203 ]\n",
      "   [0.8432209  0.87067187 0.8942013 ]\n",
      "   ...\n",
      "   [0.16945174 0.17492196 0.14819533]\n",
      "   [0.17483549 0.17875706 0.14738451]\n",
      "   [0.17867059 0.18259215 0.1512196 ]]]]\n"
     ]
    }
   ],
   "source": [
    "for img_label in train_gen:\n",
    "    print(img_label[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "561665c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "size=256\n",
    "test_data=ImageDataGenerator(\n",
    "rescale=1./255,horizontal_flip=True,rotation_range=20)\n",
    "test_gen=test_data.flow_from_directory(\n",
    "    \"C:\\\\Users\\\\SHRIRAJ\\\\Pictures\\\\training images\\\\test\",\n",
    "    target_size=(size,size),class_mode=\"sparse\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8651ddc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "size=256\n",
    "val_data=ImageDataGenerator(\n",
    "rescale=1./255,horizontal_flip=True,rotation_range=20)\n",
    "val_gen=val_data.flow_from_directory(\n",
    "    \"C:\\\\Users\\\\SHRIRAJ\\\\Pictures\\\\training images\\\\val\",\n",
    "    target_size=(size,size),class_mode=\"sparse\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc2ca302",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels=3\n",
    "input_shape=(size,size,channels)\n",
    "n_channels=3\n",
    "model=models.Sequential([\n",
    "    layers.InputLayer(input_shape=input_shape),\n",
    "    layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(n_channels,activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebf5bd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 203,075\n",
      "Trainable params: 203,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03f9bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4379af72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 4/47 [=>............................] - ETA: 1:11 - loss: 0.6591 - accuracy: 0.6857WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 940 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 6 batches). You may need to use the repeat() function when building your dataset.\n",
      "47/47 [==============================] - 9s 139ms/step - loss: 0.6591 - accuracy: 0.6857 - val_loss: 0.6375 - val_accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "    history=model.fit(\n",
    "        train_gen,steps_per_epoch=47,batch_size=17,\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=6,\n",
    "        verbose=1,\n",
    "        epochs=20,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a2e8e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 1s/step - loss: 0.6255 - accuracy: 0.6949\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3cac13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
